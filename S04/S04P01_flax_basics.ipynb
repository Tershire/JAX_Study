{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baa32933-af20-4005-9447-3751782b514d",
   "metadata": {},
   "source": [
    "**S04P01_flax_basics.ipynb**\n",
    "\n",
    "Arz\n",
    "\n",
    "2024 APR 25 (THU)\n",
    "\n",
    "reference:\n",
    "\n",
    "- https://flax.readthedocs.io/en/latest/guides/flax_fundamentals/flax_basics.html\n",
    "- https://github.com/Tershire/JAX_Study/blob/master/S02/S02P01_tutorial_jax_as_accelerated_numpy.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c8e588-5618-429a-a501-6bc9c9805020",
   "metadata": {},
   "source": [
    "# setting up out environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55a1baec-01b9-457d-a171-a9bd4075abf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "533740cc-1cd8-47b8-9310-620c98b83e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flax\n",
    "from flax import linen as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b565adc6-d667-4103-849f-e54e3405ea6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Callable, Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a14f2cb-1c8d-4af5-a9f0-c35210e00264",
   "metadata": {},
   "source": [
    "# linear regression with Flax\n",
    "\n",
    "linear regression can also be written as a single dense neural network layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ba9364-1192-4d89-9bfe-5eff5c9aa7c4",
   "metadata": {},
   "source": [
    "## ex) dense layer\n",
    "\n",
    "models (including layers) are subclasses of flax.linen.Module class.\n",
    "\n",
    "https://flax.readthedocs.io/en/v0.5.3/_autosummary/flax.linen.Dense.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35f798d8-5e9f-443d-bbbb-8c25eb846181",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Dense(features=3)  # output dimension is 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e3b98d-b562-4572-aa5e-e9353a858aa7",
   "metadata": {},
   "source": [
    "### model parameters & initialization\n",
    "\n",
    "⚠️ parameters are not stored with the models themselves. \n",
    "\n",
    "you need to initialize parameters by calling the **init** function, using a PRNGKey and dummy input data.\n",
    "\n",
    "- dummy input data informs the model of the input number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc4b3eca-ebd7-4413-827b-ce19e5f05110",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-26 15:45:12.189172: W external/xla/xla/service/gpu/nvptx_compiler.cc:718] The NVIDIA driver's CUDA version is 12.2 which is older than the ptxas CUDA version (12.4.131). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    }
   ],
   "source": [
    "key1, key2 = jax.random.split(jax.random.key(0))\n",
    "\n",
    "x = jax.random.normal(key1, (7,))  # dummy input data\n",
    "params = model.init(key2, x)  # initialize model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1e6e3c4-9567-4912-ab6d-e9317fdfb2e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'params': {'bias': (3,), 'kernel': (7, 3)}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check dimensions\n",
    "jax.tree_util.tree_map(lambda x: x.shape, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed992a7d-1853-4b53-9d47-eeaca256a93b",
   "metadata": {},
   "source": [
    "Flax is row-based system, so a vector is represented as a row.\n",
    "\n",
    "'kernel' (W) has shape (#input, #output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cdcc63-a5c5-45cf-8fc7-af37e287e59e",
   "metadata": {},
   "source": [
    "### forward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54352d9b-bb99-4b7f-a6f2-eddf2142c318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([ 1.3483415 , -0.4280271 , -0.10713735], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.apply(params, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bb7d9c-2101-42fc-8415-01dc819f464f",
   "metadata": {},
   "source": [
    "### gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "019693d3-59bc-49ee-b556-2fdcfa66eac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: (30, 7) y shape: (30, 3)\n"
     ]
    }
   ],
   "source": [
    "# data setup & generation\n",
    "num_samples = 30\n",
    "x_dim = 7  # input\n",
    "y_dim = 3  # output\n",
    "\n",
    "#\n",
    "key = jax.random.key(0)\n",
    "_, *subkeys = jax.random.split(key, 3)\n",
    "key_W, key_b = subkeys[0], subkeys[1]\n",
    "\n",
    "W = jax.random.normal(key_W, (x_dim, y_dim))\n",
    "b = jax.random.normal(key_b, (y_dim,))\n",
    "\n",
    "original_params = flax.core.freeze({\"params\": {\"bias\": b, \"kernel\": W}})\n",
    "\n",
    "#\n",
    "_, *subkeys = jax.random.split(key_W, 3)\n",
    "key_sample, key_noise = subkeys[0], subkeys[1]\n",
    "\n",
    "x_samples = jax.random.normal(key_sample, (num_samples, x_dim))\n",
    "noise = 0.1 * jax.random.normal(key_noise, (num_samples, y_dim))\n",
    "y_samples = jnp.dot(x_samples, W) + b + noise\n",
    "\n",
    "print(\"x shape:\", x_samples.shape, \"y shape:\", y_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8afc9673-1a15-4259-8f4c-6c5c58c79588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "def mean_squared_error(params, x_batch, y_batch): \n",
    "    # for a single pair (x, y)\n",
    "    def squared_error(x, y):    \n",
    "        y_pred = model.apply(params, x)\n",
    "        return jnp.inner(y - y_pred, y - y_pred)\n",
    "\n",
    "    # vectorize\n",
    "    return jnp.mean(jax.vmap(squared_error)(x_batch, y_batch), axis=0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48550223-7546-4d4e-8de9-1d9b134766ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_grad_function = jax.value_and_grad(mean_squared_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faa79a4-8926-4f76-9fb5-28b22096882a",
   "metadata": {},
   "source": [
    "unlike the JAX example, this update_params() takes in grads.\n",
    "\n",
    "in the former case, jax.grad() was inside the function. why (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb5624d7-ada4-447a-b547-13f903e4809d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param.s update\n",
    "@jax.jit\n",
    "def update_params(params, alpha, grads):\n",
    "    \"\"\"\n",
    "    alpha: learning rate\n",
    "    \"\"\"\n",
    "    params = jax.tree_util.tree_map(lambda p, g: p - alpha * g, params, grads)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ad3772e-eb3e-4c78-99a9-ee1ad1000b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at step   0: 33.618389129639\n",
      "loss at step  10: 0.044064313173\n",
      "loss at step  20: 0.027380581945\n",
      "loss at step  30: 0.027127481997\n",
      "loss at step  40: 0.027123507112\n",
      "loss at step  50: 0.027123449370\n",
      "loss at step  60: 0.027123443782\n",
      "loss at step  70: 0.027123438194\n",
      "loss at step  80: 0.027123436332\n",
      "loss at step  90: 0.027123436332\n",
      "loss at step  99: 0.027123434469\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "alpha = 0.3\n",
    "\n",
    "max_step = 100\n",
    "for i in range(max_step):\n",
    "    loss, grads = loss_grad_function(params, x_samples, y_samples)\n",
    "    params = update_params(params, alpha, grads)\n",
    "\n",
    "    if i % 10 == 0 or i == max_step - 1:\n",
    "        print(f\"loss at step {i:3.0F}: {loss:.12F}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e691f69-de5e-483b-9cda-413c06eb99bd",
   "metadata": {},
   "source": [
    "### optimizing with Optax\n",
    "\n",
    "- 1. choose optimization method (ex. adam).\n",
    "- 2. initialize optimizer state given model parameters.\n",
    "- 3. compute loss gradients using *jax.value_and_grad()*\n",
    "- 4. at every iteration,\n",
    " \n",
    "        - call *update()* to update optimizer state and model parameters.\n",
    "        - call *apply_updates()* to update model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "368aed0b-4f29-40f4-8b4c-d95c1aaa6072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68a65915-0265-46ee-bae2-2a4709dfd880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model parameters\n",
    "params = model.init(key2, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01e20c01-2867-43f9-a7e3-bcfd34421ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create optimizer\n",
    "optimizer = optax.adam(learning_rate=alpha)\n",
    "optimizer_state = optimizer.init(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32ca4aaf-01f5-438e-87dc-eeb831232277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at step   0: 33.618389129639\n",
      "loss at step  10: 4.037739753723\n",
      "loss at step  20: 1.026890873909\n",
      "loss at step  30: 0.303563058376\n",
      "loss at step  40: 0.205362066627\n",
      "loss at step  50: 0.078522302210\n",
      "loss at step  60: 0.046105630696\n",
      "loss at step  70: 0.034731782973\n",
      "loss at step  80: 0.029582021758\n",
      "loss at step  90: 0.027837540954\n",
      "loss at step  99: 0.027524823323\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "max_step = 100\n",
    "for i in range(max_step):\n",
    "    loss, grads = loss_grad_function(params, x_samples, y_samples)\n",
    "    params_update, optimizer_state = optimizer.update(grads, optimizer_state)\n",
    "    params = optax.apply_updates(params, params_update)\n",
    "    \n",
    "    if i % 10 == 0 or i == max_step - 1:\n",
    "        print(f\"loss at step {i:3.0F}: {loss:.12F}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336e2758-e942-4111-baa0-b3cc2362eaab",
   "metadata": {},
   "source": [
    "### serializing the result\n",
    "\n",
    "{save, load} model parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e490aef-16f9-49f8-b077-cc976fa1dfe0",
   "metadata": {},
   "source": [
    "- **save**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ffb5ed8-762c-491b-b1cd-4a402c540d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'params': {'bias': Array([ 0.09807936, -1.1808372 , -0.2617658 ], dtype=float32), 'kernel': Array([[-1.8411863 , -0.50547993,  0.55073863],\n",
      "       [-1.2407506 , -0.6748584 , -0.7191346 ],\n",
      "       [ 1.1142238 , -2.4242043 ,  0.07755796],\n",
      "       [ 0.46512845,  0.80414766, -1.4551915 ],\n",
      "       [-1.2403113 , -2.006448  ,  0.5853151 ],\n",
      "       [-0.9453332 ,  0.9392538 ,  0.40514505],\n",
      "       [ 0.2739672 , -0.30546483,  0.04342157]], dtype=float32)}}\n"
     ]
    }
   ],
   "source": [
    "saved_params_as_dict = flax.serialization.to_state_dict(params)\n",
    "print(saved_params_as_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "573f9bd0-3ea8-40df-90f3-e5fa3f9d9bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\x81\\xa6params\\x82\\xa4bias\\xc7\\x19\\x01\\x93\\x91\\x03\\xa7float32\\xc4\\x0c\\xd5\\xdd\\xc8=\\xac%\\x97\\xbf+\\x06\\x86\\xbe\\xa6kernel\\xc7b\\x01\\x93\\x92\\x07\\x03\\xa7float32\\xc4T\\xfe\\xab\\xeb\\xbf\"g\\x01\\xbf5\\xfd\\x0c?\\xea\\xd0\\x9e\\xbf\\x85\\xc3,\\xbf5\\x198\\xbf\\xe3\\x9e\\x8e?*&\\x1b\\xc0\\xb5\\xd6\\x9e=Q%\\xee>\\x9f\\xdcM?\\xb7C\\xba\\xbf\\x85\\xc2\\x9e\\xbf\\xa5i\\x00\\xc06\\xd7\\x15?[\\x01r\\xbf\\xf0rp?,o\\xcf>nE\\x8c>\\xe3e\\x9c\\xbe\\xd2\\xda1='\n"
     ]
    }
   ],
   "source": [
    "saved_params_as_bytes = flax.serialization.to_bytes(params)\n",
    "print(saved_params_as_bytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3c2ed8-e227-493a-bb90-d50734fa34f3",
   "metadata": {},
   "source": [
    "- **load**\n",
    "\n",
    "need to provide a parameter template as the first argument, so that the load function can recognize the parameters structure.\n",
    "\n",
    "here, **params** will not be modified but will provide the template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e67643a-2633-446f-8a18-bacf2aba098d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'params': {'bias': Array([ 0.09807936, -1.1808372 , -0.2617658 ], dtype=float32), 'kernel': Array([[-1.8411863 , -0.50547993,  0.55073863],\n",
      "       [-1.2407506 , -0.6748584 , -0.7191346 ],\n",
      "       [ 1.1142238 , -2.4242043 ,  0.07755796],\n",
      "       [ 0.46512845,  0.80414766, -1.4551915 ],\n",
      "       [-1.2403113 , -2.006448  ,  0.5853151 ],\n",
      "       [-0.9453332 ,  0.9392538 ,  0.40514505],\n",
      "       [ 0.2739672 , -0.30546483,  0.04342157]], dtype=float32)}}\n"
     ]
    }
   ],
   "source": [
    "loaded_params_from_dict = flax.serialization.from_state_dict(params, saved_params_as_dict)\n",
    "print(loaded_params_from_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b10fadb1-54c4-4d1d-8c1e-44e5aec00e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'params': {'bias': array([ 0.09807936, -1.1808372 , -0.2617658 ], dtype=float32), 'kernel': array([[-1.8411863 , -0.50547993,  0.55073863],\n",
      "       [-1.2407506 , -0.6748584 , -0.7191346 ],\n",
      "       [ 1.1142238 , -2.4242043 ,  0.07755796],\n",
      "       [ 0.46512845,  0.80414766, -1.4551915 ],\n",
      "       [-1.2403113 , -2.006448  ,  0.5853151 ],\n",
      "       [-0.9453332 ,  0.9392538 ,  0.40514505],\n",
      "       [ 0.2739672 , -0.30546483,  0.04342157]], dtype=float32)}}\n"
     ]
    }
   ],
   "source": [
    "loaded_params_from_bytes = flax.serialization.from_bytes(params, saved_params_as_bytes)\n",
    "print(loaded_params_from_bytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f9a096-f023-41e8-996f-66e9ee0836b9",
   "metadata": {},
   "source": [
    "# defining your own models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413ead75-0410-44e7-9ff5-a43397c06d34",
   "metadata": {},
   "source": [
    "## ex) multi-layer perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "71a5b11e-c552-4edc-b3fe-8f1abc894334",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Explicit_MLP(nn.Module):\n",
    "    features: Sequence[int]  # sequence of output feature dimension per layer\n",
    "\n",
    "    def setup(self):\n",
    "        self.layers = [nn.Dense(feature) for feature in self.features]\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        x = inputs\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            x = layer(x)\n",
    "            if i is not len(self.layers) - 1:\n",
    "                x = nn.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "99307fb0-5d8c-48d0-a9ef-b409d0f60f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params shape:\n",
      " {'params': {'layers_0': {'bias': (9,), 'kernel': (7, 9)}, 'layers_1': {'bias': (5,), 'kernel': (9, 5)}, 'layers_2': {'bias': (3,), 'kernel': (5, 3)}}}\n",
      "y:\n",
      " [[-0.10174     0.468905    0.2727127 ]\n",
      " [-0.40046442  0.5607383   0.3304994 ]\n",
      " [-0.23100257  0.57434875  0.2876985 ]\n",
      " [-0.3043432   0.463985    0.27915537]\n",
      " [-0.21458422  0.5588921   0.3658545 ]\n",
      " [-0.5424561   0.9484465   0.5600072 ]\n",
      " [-0.19780068  0.3608388   0.17913571]\n",
      " [-0.2271311   0.55443084  0.3432787 ]\n",
      " [-0.13232163  0.49851972  0.32358307]\n",
      " [-0.51897645  0.73706603  0.43027398]]\n"
     ]
    }
   ],
   "source": [
    "# input\n",
    "_, *subkeys = jax.random.split(jax.random.key(0), 3)\n",
    "key1, key2 = subkeys[0], subkeys[1]\n",
    "\n",
    "num_samples = 10\n",
    "x_dim = 7\n",
    "x = jax.random.uniform(key1, (num_samples, x_dim))\n",
    "\n",
    "# model\n",
    "model = Explicit_MLP(features=[9, 5, 3])\n",
    "params = model.init(key2, x)\n",
    "\n",
    "# output\n",
    "y = model.apply(params, x)\n",
    "\n",
    "print(\"params shape:\\n\", jax.tree_util.tree_map(jnp.shape, flax.core.unfreeze(params)))  # (?)\n",
    "print(\"y:\\n\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3070da-98d2-4d54-9e62-cd7f35954b0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
